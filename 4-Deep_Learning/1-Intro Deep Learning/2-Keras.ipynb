{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "     -------------------------------------- 266.3/266.3 MB 8.2 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     --------------------------------------- 24.4/24.4 MB 31.1 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 47.6 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\joan oliver\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp37-cp37m-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 32.7 MB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "     ------------------------------------- 896.6/896.6 kB 55.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 33.6 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.6)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 38.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (40.8.0)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.5/64.5 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.9/93.9 kB ? eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     ------------------------------------- 233.6/233.6 kB 14.0 MB/s eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 35.0 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.19.1-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 181.3/181.3 kB ? eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 181.3/181.3 kB ? eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.11.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.9/83.9 kB ? eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, setuptools, pyasn1, protobuf, opt-einsum, oauthlib, keras, h5py, grpcio, google-pasta, gast, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, astunparse, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.0\n",
      "    Uninstalling protobuf-4.23.0:\n",
      "      Successfully uninstalled protobuf-4.23.0\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.19.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.54.2 h5py-3.8.0 keras-2.11.0 libclang-16.0.0 markdown-3.4.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 setuptools-67.8.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-2.2.3 wheel-0.40.0 wrapt-1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "web3 6.3.0 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\joan oliver\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbE0lEQVR4nO3df2xV9f3H8dd10AL1FsKvVqpBfuofBAjISjOglaoBA0HCZAMXxSxbBDKDMUNxbogaGJgBSyluLAgkZIQJdGPJKKUBDDgok7gCTmBCIXDbXot1vVcsvSLn+wfxfrlSwM/l3r5vL89HchJ673n3fDye8OS2t6c+SZ4AAGhjd1kvAABwZyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARAfrBbSmT58+CofD1ssAAMTJ7/ertrb2pvukXID69OmjQCBgvQwAwG3Ky8u7aYRS7ktwvPIBgPRwq7/PkxagOXPmqKamRs3NzTp48KBGjRqVrEMBANqhpARo+vTpWr58uRYtWqQRI0aourpaO3fuVK9evZJxOABAO+RTEu6GffDgQf3rX//SL37xi6sH8fl07tw5lZSUaOnSpTed9fv9CoVCiV4SAKCNZWdn3/TLcAl/BdSxY0eNHDlSlZWV0cc8z1NlZaUKCgqu2z8jI0N+vz9mAwCkv4QHqGfPnurQoYOCwWDM48FgULm5udftv2DBAoVCoejGO+AA4M5g/i64JUuWKDs7O7rl5eVZLwkA0AYS/nNAFy5c0OXLl5WTkxPzeE5Ojurr66/bPxKJKBKJJHoZAIAUl/BXQF999ZUOHz6s4uLi6GM+n0/FxcU6cOBAog8HAGinknInhOXLl2vDhg364IMPdOjQIc2bN09ZWVlat25dMg4HAGiHkhKgv/zlL+rVq5def/115ebm6t///rcmTJigTz/9NBmHAwC0Q0n5OaDbwc8BAUB6aPOfAwIA4LsgQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHSwXgCQSq5cueI809LSkoSVJMaGDRvimrt48aLzzH/+8x/nmZUrVzrPvPLKK84zq1atcp6RpM6dOzvP/O53v3OemT17tvNMOuAVEADABAECAJhIeIAWLlwoz/Nito8//jjRhwEAtHNJ+R7QsWPH9Mgjj0Q/vnz5cjIOAwBox5ISoMuXLysYDCbjUwMA0kRSvgc0aNAgBQIBnTp1Shs3btR99913w30zMjLk9/tjNgBA+kt4gKqqqjRr1ixNmDBBs2fPVr9+/bRv3z7dfffdre6/YMEChUKh6BYIBBK9JABACkp4gMrLy7VlyxYdPXpUFRUVevzxx9WtWzdNnz691f2XLFmi7Ozs6JaXl5foJQEAUlDSfxC1qalJJ0+e1MCBA1t9PhKJKBKJJHsZAIAUk/SfA8rKytKAAQNUV1eX7EMBANqRhAforbfe0rhx49S3b18VFBSorKxMX3/9tTZt2pToQwEA2rGEfwnu3nvv1aZNm9SjRw81NDRo//79Gj16tC5cuJDoQwEA2rGEB2jGjBmJ/pRIUU1NTc4zX3/9tfNMdXW180xFRYXzjCT973//c55Zs2ZNXMdKN/fff7/zzIsvvug8s3btWueZrl27Os9I0tixY51nxo8fH9ex7kTcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMOGT5Fkv4lp+v1+hUMh6GXeU8+fPxzU3fPhw55nPP/88rmOhbd11l/u/TXft2uU807lzZ+eZePTu3Tuuubvvvtt5plevXnEdKx1lZ2crHA7f8HleAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEB+sFwF6PHj3imsvJyXGe4W7YVz322GPOM/H8f9q2bZvzjCRlZmY6zxQVFcV1LNy5eAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqRQ586d45pbv36988yWLVucZwoKCpxnpk2b5jwTrzFjxjjP/O1vf3OeycjIcJ6pr693npGk3//+93HNAS54BQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPBJ8qwXcS2/369QKGS9DCRJS0uL80w8N+F85ZVXnGckadmyZc4ze/bscZ4ZN26c8wzQ3mRnZyscDt/weV4BAQBMECAAgAnnAI0dO1bbt29XIBCQ53maMmXKdfssWrRItbW1+vLLL7Vr1y4NHDgwIYsFAKQP5wBlZWWpurpac+fObfX5+fPn6/nnn9dzzz2n/Px8Xbx4UTt37lRmZuZtLxYAkD6cfyNqeXm5ysvLb/j8vHnz9Oabb2r79u2SpKefflrBYFBPPPGENm/eHP9KAQBpJaHfA+rXr5/uueceVVZWRh8LhUKqqqq64a9VzsjIkN/vj9kAAOkvoQHKzc2VJAWDwZjHg8Fg9LlvW7BggUKhUHQLBAKJXBIAIEWZvwtuyZIlys7Ojm55eXnWSwIAtIGEBqi+vl6SlJOTE/N4Tk5O9Llvi0QiCofDMRsAIP0lNEA1NTWqq6tTcXFx9DG/36/8/HwdOHAgkYcCALRzzu+Cy8rKivm5nn79+mnYsGFqbGzUuXPntHLlSr366qv673//q5qaGr3xxhuqra3VX//610SuGwDQzjkH6KGHHtLevXujH69YsUKStH79ej377LNatmyZsrKytGbNGnXr1k379+/XhAkT4roHGAAgfXEzUqSleG4qKl19V6arqVOnOs+8++67zjM+n895BrDEzUgBACmJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgbNtJSJBKJa27mzJnOM2VlZc4z1dXVzjNDhgxxngEscTdsAEBKIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNS4BqNjY3OMwMGDHCe6d69u/PME0884Tzzgx/8wHlGkqZOneo84/P54joW0hc3IwUApCQCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwVu06FDh5xnJkyY4DzT1NTkPBOvd955x3lm2rRpzjN333238wzaD25GCgBISQQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GChioq6tznnnhhRecZ959913nmXj96le/cp755S9/6Tzj9/udZ2CDm5ECAFISAQIAmHAO0NixY7V9+3YFAgF5nqcpU6bEPL9u3Tp5nhez7dixI2ELBgCkB+cAZWVlqbq6WnPnzr3hPjt27FBubm50mzFjxm0tEgCQfjq4DpSXl6u8vPym+7S0tCgYDMa9KABA+kvK94CKiooUDAZ1/PhxrV69Wt27d7/hvhkZGfL7/TEbACD9JTxA5eXlevrpp1VcXKyXXnpJhYWF2rFjh+66q/VDLViwQKFQKLoFAoFELwkAkIKcvwR3K5s3b47++dixYzpy5IhOnz6toqIi7d69+7r9lyxZouXLl0c/9vv9RAgA7gBJfxt2TU2NGhoaNHDgwFafj0QiCofDMRsAIP0lPUB5eXnq0aNHXD/5DQBIX85fgsvKyop5NdOvXz8NGzZMjY2Namxs1MKFC7V161bV19drwIABWrZsmT755BPt3LkzoQsHALRvzgF66KGHtHfv3ujHK1askCStX79es2fP1tChQ/XMM8+oW7duqq2tVUVFhX79618rEokkbNEAgPaPm5EC7cSlS5ecZw4ePBjXsR555BHnGc9z/6vkhz/8ofPMtW90QmrjZqQAgJREgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9wNG8B1MjMznWcuX77sPNOhg/NvhNGRI0ecZx544AHnGdw+7oYNAEhJBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJ9zsBArhttbW1zjPbtm1znjlw4IDzjBTfjUXjMWrUKOeZwYMHJ2ElsMArIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBa7R0NDgPFNaWuo8s27dOueZ8+fPO8+0pe9973vOM/fff7/zjM/nc55BauIVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRIuV98cUXzjN///vf4zrW66+/7jxz8uTJuI6VysaPH+8889vf/tZ5ZuTIkc4zSB+8AgIAmCBAAAATTgF6+eWXdejQIYVCIQWDQZWVlWnw4MEx+2RmZmrVqlW6cOGCwuGwtmzZot69eyd00QCA9s8pQIWFhSotLdXo0aP16KOPqmPHjqqoqFCXLl2i+6xYsUKTJ0/Wk08+qcLCQvXp00fbtm1L+MIBAO2b05sQJk6cGPPxrFmz1NDQoJEjR2rfvn3Kzs7WT3/6U82cOVN79uyRJD377LM6fvy48vPzVVVVlbiVAwDatdv6HlDXrl0lSY2NjZKuvqMlIyNDlZWV0X1OnDihs2fPqqCgoNXPkZGRIb/fH7MBANJf3AHy+XxauXKl9u/fr48++kiSlJubq5aWFjU1NcXsGwwGlZub2+rnWbBggUKhUHQLBALxLgkA0I7EHaDS0lINGTJEP/7xj29rAUuWLFF2dnZ0y8vLu63PBwBoH+L6QdSSkhJNmjRJ48aNi3nFUl9fr8zMTHXt2jXmVVBOTo7q6+tb/VyRSESRSCSeZQAA2jHnV0AlJSWaOnWqxo8frzNnzsQ8d/jwYUUiERUXF0cfGzx4sPr27asDBw7c9mIBAOnD6RVQaWmpZs6cqSlTpigcDisnJ0eS1NTUpEuXLikUCmnt2rVavny5GhsbFQqFVFJSon/+85+8Aw4AEMMpQHPmzJEkvffeezGPz5o1Sxs2bJAkvfDCC7py5Yq2bt2qzMxM7dy5MzoHAMA3fJI860Vcy+/3KxQKWS8D38HFixedZ86dO+c885Of/MR55sMPP3SeSXWPPfaY88yiRYviOtaoUaOcZ3w+X1zHQvrKzs5WOBy+4fPcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm4vqNqEhdzc3NzjPz5s2L61j79+93njl+/Hhcx0pljz/+uPPMb37zG+eZ4cOHO8907NjReQZoK7wCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDPSNnLmzBnnmcWLFzvPVFZWOs+cPXvWeSbVdenSJa65N954w3lmzpw5zjMZGRnOM0C64RUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5G2ka1btzrPrF27NgkrSZwRI0Y4z8yYMcN5pkMH98v05z//ufOMJHXq1CmuOQDueAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjwSfKsF3Etv9+vUChkvQwAwG3Kzs5WOBy+4fO8AgIAmCBAAAATTgF6+eWXdejQIYVCIQWDQZWVlWnw4MEx++zZs0ee58Vsb7/9dkIXDQBo/5wCVFhYqNLSUo0ePVqPPvqoOnbsqIqKCnXp0iVmvzVr1ig3Nze6zZ8/P6GLBgC0f06/anLixIkxH8+aNUsNDQ0aOXKk9u3bF338yy+/VDAYTMwKAQBp6ba+B9S1a1dJUmNjY8zjTz31lBoaGnT06FEtXrxYnTt3vuHnyMjIkN/vj9kAAOkv7rdh+3w+bd++Xd26ddPYsWOjj//sZz/T2bNnVVtbq6FDh2rp0qU6dOiQpk2b1urnWbhwoV577bV4lgAASGG3eht23AFavXq1Jk6cqDFjxigQCNxwv4cffli7d+/WgAEDdPr06euez8jIUGZmZvRjv99/088HAGgfbhUgp+8BfaOkpESTJk3SuHHjbhmLqqoqSdLAgQNbDVAkElEkEolnGQCAdsw5QCUlJZo6daqKiop05syZW+4/fPhwSVJdXZ3roQAAacwpQKWlpZo5c6amTJmicDisnJwcSVJTU5MuXbqk/v37a+bMmfrHP/6hzz77TEOHDtWKFSv03nvv6ejRo0n5DwAAtE9O3wPyvNZ3nTVrljZs2KB7771XGzdu1JAhQ5SVlaVz586prKxMb7755k2/Dngt7gUHAOkhaW9CSBYCBADpgZuRAgBSEgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhIuQD5/X7rJQAAEuBWf5/7JHlts5Tvrk+fPgqHw9c97vf7FQgElJeX1+rzdwrOw1Wch6s4D1dxHq5KlfPg9/tVW1t70306tNFanNxq0eFw+I6+wL7BebiK83AV5+EqzsNV1ufhuxw75b4EBwC4MxAgAICJdhWglpYWvfbaa2ppabFeiinOw1Wch6s4D1dxHq5qT+chJd+EAABIf+3qFRAAIH0QIACACQIEADBBgAAAJtpNgObMmaOamho1Nzfr4MGDGjVqlPWS2tzChQvleV7M9vHHH1svK+nGjh2r7du3KxAIyPM8TZky5bp9Fi1apNraWn355ZfatWuXBg4caLDS5LrVeVi3bt1118eOHTuMVpscL7/8sg4dOqRQKKRgMKiysjINHjw4Zp/MzEytWrVKFy5cUDgc1pYtW9S7d2+jFSfHdzkPe/bsue56ePvtt41W3Lp2EaDp06dr+fLlWrRokUaMGKHq6mrt3LlTvXr1sl5amzt27Jhyc3Oj25gxY6yXlHRZWVmqrq7W3LlzW31+/vz5ev755/Xcc88pPz9fFy9e1M6dO5WZmdnGK02uW50HSdqxY0fM9TFjxow2XGHyFRYWqrS0VKNHj9ajjz6qjh07qqKiQl26dInus2LFCk2ePFlPPvmkCgsL1adPH23bts1w1Yn3Xc6DJK1Zsybmepg/f77Rim/MS/Xt4MGDXklJSfRjn8/nnT9/3nvppZfM19aW28KFC70PP/zQfB2Wm+d53pQpU2Ieq62t9V588cXox9nZ2V5zc7P3ox/9yHy9bXke1q1b55WVlZmvrS23nj17ep7neWPHjo3+v29pafGmTZsW3eeBBx7wPM/z8vPzzdfbVudBkrdnzx5vxYoV5mu72Zbyr4A6duyokSNHqrKyMvqY53mqrKxUQUGB4cpsDBo0SIFAQKdOndLGjRt13333WS/JVL9+/XTPPffEXB+hUEhVVVV35PVRVFSkYDCo48ePa/Xq1erevbv1kpKqa9eukqTGxkZJ0siRI5WRkRFzPZw4cUJnz55N6+vh2+fhG0899ZQaGhp09OhRLV68WJ07d7ZY3g2l5M1Ir9WzZ0916NBBwWAw5vFgMKgHH3zQaFU2qqqqNGvWLJ04cUL33HOPFi5cqH379mnIkCH64osvrJdnIjc3V5JavT6+ee5OUV5erm3btqmmpkYDBgzQ4sWLtWPHDhUUFOjKlSvWy0s4n8+nlStXav/+/froo48kXb0eWlpa1NTUFLNvOl8PrZ0HSfrzn/+ss2fPqra2VkOHDtXSpUv1wAMPaNq0aYarjZXyAcL/Ky8vj/756NGjqqqq0tmzZzV9+nS98847hitDKti8eXP0z8eOHdORI0d0+vRpFRUVaffu3YYrS47S0lINGTLkjvg+6M3c6Dz86U9/iv752LFjqqur0+7du9W/f3+dPn26rZfZqpT/EtyFCxd0+fJl5eTkxDyek5Oj+vp6o1WlhqamJp08eTIt3/H1XX1zDXB9XK+mpkYNDQ1peX2UlJRo0qRJevjhhxUIBKKP19fXKzMzM/olqW+k6/Vwo/PQmqqqKklKqesh5QP01Vdf6fDhwyouLo4+5vP5VFxcrAMHDhiuzF5WVpYGDBiguro666WYqampUV1dXcz14ff7lZ+ff8dfH3l5eerRo0faXR8lJSWaOnWqxo8frzNnzsQ8d/jwYUUikZjrYfDgwerbt2/aXQ83Ow+tGT58uCSl3PVg/k6IW23Tp0/3mpubvaefftp78MEHvT/84Q9eY2Oj17t3b/O1teX21ltveePGjfP69u3rFRQUeBUVFd6nn37q9ezZ03xtydyysrK8YcOGecOGDfM8z/PmzZvnDRs2zLvvvvs8Sd78+fO9xsZGb/Lkyd6QIUO8srIy79SpU15mZqb52tvqPGRlZXnLli3z8vPzvb59+3rjx4/3PvjgA+/EiRNeRkaG+doTtZWWlnqff/65N27cOC8nJye6derUKbrP6tWrvTNnznhFRUXeiBEjvPfff997//33zdfeluehf//+3quvvuqNGDHC69u3rzd58mTvk08+8fbu3Wu+9m9t5gv4TtvcuXO9M2fOeJcuXfIOHjzoff/73zdfU1tvmzZt8gKBgHfp0iXv3Llz3qZNm7z+/fubryvZW2FhodeadevWRfdZtGiRV1dX5zU3N3u7du3yBg0aZL7utjwPnTp18srLy71gMOi1tLR4NTU13h//+Me0+0fajTzzzDPRfTIzM71Vq1Z5n332mffFF194W7du9XJycszX3pbn4d577/X27t3rXbhwwWtubvZOnjzpLV261PP7/eZrv3bj1zEAAEyk/PeAAADpiQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw8X/gB+pzuv098gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x00000224830D5A08>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 3s 4ms/step - loss: 1.3255 - accuracy: 0.6701 - val_loss: 0.6281 - val_accuracy: 0.8620\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.5372 - accuracy: 0.8661 - val_loss: 0.4044 - val_accuracy: 0.8957\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.4088 - accuracy: 0.8893 - val_loss: 0.3393 - val_accuracy: 0.9063\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.9020 - val_loss: 0.3065 - val_accuracy: 0.9141\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.3243 - accuracy: 0.9095 - val_loss: 0.2853 - val_accuracy: 0.9174\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.3023 - accuracy: 0.9148 - val_loss: 0.2691 - val_accuracy: 0.9231\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.9199 - val_loss: 0.2553 - val_accuracy: 0.9274\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.9238 - val_loss: 0.2443 - val_accuracy: 0.9318\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2581 - accuracy: 0.9271 - val_loss: 0.2344 - val_accuracy: 0.9342\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2471 - accuracy: 0.9306 - val_loss: 0.2267 - val_accuracy: 0.9360\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2374 - accuracy: 0.9335 - val_loss: 0.2186 - val_accuracy: 0.9390\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2283 - accuracy: 0.9354 - val_loss: 0.2109 - val_accuracy: 0.9416\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2198 - accuracy: 0.9380 - val_loss: 0.2058 - val_accuracy: 0.9419\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2124 - accuracy: 0.9398 - val_loss: 0.1977 - val_accuracy: 0.9458\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2053 - accuracy: 0.9416 - val_loss: 0.1927 - val_accuracy: 0.9472\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1987 - accuracy: 0.9435 - val_loss: 0.1872 - val_accuracy: 0.9480\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1924 - accuracy: 0.9452 - val_loss: 0.1831 - val_accuracy: 0.9504\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1863 - accuracy: 0.9471 - val_loss: 0.1783 - val_accuracy: 0.9513\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1804 - accuracy: 0.9485 - val_loss: 0.1743 - val_accuracy: 0.9528\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1751 - accuracy: 0.9498 - val_loss: 0.1699 - val_accuracy: 0.9537\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1702 - accuracy: 0.9516 - val_loss: 0.1656 - val_accuracy: 0.9560\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1653 - accuracy: 0.9536 - val_loss: 0.1624 - val_accuracy: 0.9564\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1606 - accuracy: 0.9545 - val_loss: 0.1577 - val_accuracy: 0.9577\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1564 - accuracy: 0.9559 - val_loss: 0.1542 - val_accuracy: 0.9590\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1521 - accuracy: 0.9571 - val_loss: 0.1520 - val_accuracy: 0.9594\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1482 - accuracy: 0.9581 - val_loss: 0.1487 - val_accuracy: 0.9608\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1440 - accuracy: 0.9593 - val_loss: 0.1471 - val_accuracy: 0.9611\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1405 - accuracy: 0.9604 - val_loss: 0.1428 - val_accuracy: 0.9617\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1370 - accuracy: 0.9613 - val_loss: 0.1408 - val_accuracy: 0.9633\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1335 - accuracy: 0.9625 - val_loss: 0.1388 - val_accuracy: 0.9621\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.1303 - accuracy: 0.9633 - val_loss: 0.1352 - val_accuracy: 0.9639\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1271 - accuracy: 0.9638 - val_loss: 0.1362 - val_accuracy: 0.9641\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1241 - accuracy: 0.9651 - val_loss: 0.1324 - val_accuracy: 0.9654\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1213 - accuracy: 0.9659 - val_loss: 0.1290 - val_accuracy: 0.9664\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1183 - accuracy: 0.9670 - val_loss: 0.1282 - val_accuracy: 0.9666\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1157 - accuracy: 0.9675 - val_loss: 0.1266 - val_accuracy: 0.9658\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1131 - accuracy: 0.9685 - val_loss: 0.1236 - val_accuracy: 0.9679\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1105 - accuracy: 0.9692 - val_loss: 0.1225 - val_accuracy: 0.9671\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1081 - accuracy: 0.9698 - val_loss: 0.1208 - val_accuracy: 0.9683\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1057 - accuracy: 0.9708 - val_loss: 0.1190 - val_accuracy: 0.9683\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1035 - accuracy: 0.9713 - val_loss: 0.1179 - val_accuracy: 0.9684\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1012 - accuracy: 0.9724 - val_loss: 0.1165 - val_accuracy: 0.9688\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0990 - accuracy: 0.9730 - val_loss: 0.1155 - val_accuracy: 0.9695\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0972 - accuracy: 0.9732 - val_loss: 0.1149 - val_accuracy: 0.9685\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0951 - accuracy: 0.9737 - val_loss: 0.1130 - val_accuracy: 0.9696\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0931 - accuracy: 0.9745 - val_loss: 0.1115 - val_accuracy: 0.9698\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0911 - accuracy: 0.9757 - val_loss: 0.1104 - val_accuracy: 0.9706\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0893 - accuracy: 0.9761 - val_loss: 0.1090 - val_accuracy: 0.9703\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0877 - accuracy: 0.9763 - val_loss: 0.1081 - val_accuracy: 0.9707\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0858 - accuracy: 0.9770 - val_loss: 0.1067 - val_accuracy: 0.9717\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0850 - accuracy: 0.9773 - val_loss: 0.1051 - val_accuracy: 0.9711\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0820 - accuracy: 0.9778 - val_loss: 0.1082 - val_accuracy: 0.9698\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0789 - accuracy: 0.9791 - val_loss: 0.1060 - val_accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0759 - accuracy: 0.9797 - val_loss: 0.0994 - val_accuracy: 0.9716\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0732 - accuracy: 0.9804 - val_loss: 0.0980 - val_accuracy: 0.9721\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0707 - accuracy: 0.9813 - val_loss: 0.0962 - val_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0682 - accuracy: 0.9816 - val_loss: 0.0949 - val_accuracy: 0.9723\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0656 - accuracy: 0.9827 - val_loss: 0.0947 - val_accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0635 - accuracy: 0.9834 - val_loss: 0.0931 - val_accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0613 - accuracy: 0.9836 - val_loss: 0.0939 - val_accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224833d6988>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3255122900009155,\n",
       "  0.5372045040130615,\n",
       "  0.40881624817848206,\n",
       "  0.35611504316329956,\n",
       "  0.32433149218559265,\n",
       "  0.3023306429386139,\n",
       "  0.2850038409233093,\n",
       "  0.2707560658454895,\n",
       "  0.2581365704536438,\n",
       "  0.24710839986801147,\n",
       "  0.2374064326286316,\n",
       "  0.22826285660266876,\n",
       "  0.21982134878635406,\n",
       "  0.212418794631958,\n",
       "  0.20530423521995544,\n",
       "  0.1986558735370636,\n",
       "  0.19244743883609772,\n",
       "  0.1863471269607544,\n",
       "  0.18042941391468048,\n",
       "  0.17505422234535217,\n",
       "  0.17018067836761475,\n",
       "  0.16534046828746796,\n",
       "  0.16064375638961792,\n",
       "  0.1564418524503708,\n",
       "  0.15214723348617554,\n",
       "  0.14815030992031097,\n",
       "  0.1440407633781433,\n",
       "  0.14052394032478333,\n",
       "  0.13696303963661194,\n",
       "  0.13352636992931366,\n",
       "  0.1303326040506363,\n",
       "  0.1270647495985031,\n",
       "  0.12412892282009125,\n",
       "  0.12128923833370209,\n",
       "  0.11832328140735626,\n",
       "  0.11571290343999863,\n",
       "  0.11314880847930908,\n",
       "  0.11052998155355453,\n",
       "  0.10808467864990234,\n",
       "  0.10574314743280411,\n",
       "  0.10353601723909378,\n",
       "  0.10116498917341232,\n",
       "  0.0990108773112297,\n",
       "  0.09724804013967514,\n",
       "  0.09505750983953476,\n",
       "  0.09312532097101212,\n",
       "  0.09108127653598785,\n",
       "  0.08932502567768097,\n",
       "  0.08766568452119827,\n",
       "  0.0858350470662117],\n",
       " 'accuracy': [0.6701200008392334,\n",
       "  0.8660600185394287,\n",
       "  0.8892999887466431,\n",
       "  0.9020199775695801,\n",
       "  0.9095199704170227,\n",
       "  0.9147800207138062,\n",
       "  0.919920027256012,\n",
       "  0.9238399863243103,\n",
       "  0.927079975605011,\n",
       "  0.9306399822235107,\n",
       "  0.9334800243377686,\n",
       "  0.9354199767112732,\n",
       "  0.9380000233650208,\n",
       "  0.9397799968719482,\n",
       "  0.9416400194168091,\n",
       "  0.9434599876403809,\n",
       "  0.9451799988746643,\n",
       "  0.9470999836921692,\n",
       "  0.9484599828720093,\n",
       "  0.9497600197792053,\n",
       "  0.9515600204467773,\n",
       "  0.9536399841308594,\n",
       "  0.954479992389679,\n",
       "  0.9558799862861633,\n",
       "  0.9570800065994263,\n",
       "  0.9581199884414673,\n",
       "  0.9592599868774414,\n",
       "  0.9603999853134155,\n",
       "  0.9613000154495239,\n",
       "  0.9625399708747864,\n",
       "  0.9632999897003174,\n",
       "  0.9637799859046936,\n",
       "  0.9651200175285339,\n",
       "  0.9659199714660645,\n",
       "  0.9670000076293945,\n",
       "  0.9674999713897705,\n",
       "  0.9684799909591675,\n",
       "  0.969219982624054,\n",
       "  0.9697999954223633,\n",
       "  0.9708200097084045,\n",
       "  0.9712799787521362,\n",
       "  0.9724199771881104,\n",
       "  0.9729599952697754,\n",
       "  0.9731799960136414,\n",
       "  0.9737399816513062,\n",
       "  0.9745200276374817,\n",
       "  0.9756600260734558,\n",
       "  0.9760599732398987,\n",
       "  0.9763200283050537,\n",
       "  0.9769600033760071],\n",
       " 'val_loss': [0.6281177401542664,\n",
       "  0.40436363220214844,\n",
       "  0.3392876982688904,\n",
       "  0.30645108222961426,\n",
       "  0.28525736927986145,\n",
       "  0.26911675930023193,\n",
       "  0.255307137966156,\n",
       "  0.24428537487983704,\n",
       "  0.23442253470420837,\n",
       "  0.22670897841453552,\n",
       "  0.21861164271831512,\n",
       "  0.2109338939189911,\n",
       "  0.2057771235704422,\n",
       "  0.19770444929599762,\n",
       "  0.19271601736545563,\n",
       "  0.18722251057624817,\n",
       "  0.183098703622818,\n",
       "  0.17834094166755676,\n",
       "  0.17427848279476166,\n",
       "  0.16991783678531647,\n",
       "  0.1656085103750229,\n",
       "  0.1624239981174469,\n",
       "  0.15772777795791626,\n",
       "  0.15420329570770264,\n",
       "  0.15195980668067932,\n",
       "  0.148654043674469,\n",
       "  0.14706045389175415,\n",
       "  0.14280231297016144,\n",
       "  0.14080189168453217,\n",
       "  0.1387983113527298,\n",
       "  0.1351936310529709,\n",
       "  0.1362297087907791,\n",
       "  0.13241741061210632,\n",
       "  0.12896467745304108,\n",
       "  0.12823767960071564,\n",
       "  0.12662698328495026,\n",
       "  0.12356060743331909,\n",
       "  0.12246999144554138,\n",
       "  0.12082535028457642,\n",
       "  0.11897719651460648,\n",
       "  0.1178629994392395,\n",
       "  0.11649017035961151,\n",
       "  0.1155075952410698,\n",
       "  0.11489889770746231,\n",
       "  0.11295842379331589,\n",
       "  0.11151543259620667,\n",
       "  0.11040890216827393,\n",
       "  0.1089898943901062,\n",
       "  0.10812518000602722,\n",
       "  0.10673903673887253],\n",
       " 'val_accuracy': [0.8619999885559082,\n",
       "  0.8956999778747559,\n",
       "  0.9063000082969666,\n",
       "  0.9140999913215637,\n",
       "  0.9174000024795532,\n",
       "  0.9230999946594238,\n",
       "  0.9273999929428101,\n",
       "  0.9318000078201294,\n",
       "  0.9341999888420105,\n",
       "  0.9359999895095825,\n",
       "  0.9390000104904175,\n",
       "  0.9416000247001648,\n",
       "  0.9419000148773193,\n",
       "  0.9458000063896179,\n",
       "  0.9472000002861023,\n",
       "  0.9480000138282776,\n",
       "  0.9503999948501587,\n",
       "  0.9513000249862671,\n",
       "  0.9527999758720398,\n",
       "  0.9537000060081482,\n",
       "  0.9559999704360962,\n",
       "  0.9563999772071838,\n",
       "  0.9577000141143799,\n",
       "  0.9589999914169312,\n",
       "  0.9593999981880188,\n",
       "  0.9607999920845032,\n",
       "  0.9610999822616577,\n",
       "  0.9617000222206116,\n",
       "  0.9632999897003174,\n",
       "  0.9621000289916992,\n",
       "  0.9639000296592712,\n",
       "  0.9641000032424927,\n",
       "  0.965399980545044,\n",
       "  0.9664000272750854,\n",
       "  0.9666000008583069,\n",
       "  0.9657999873161316,\n",
       "  0.9678999781608582,\n",
       "  0.9671000242233276,\n",
       "  0.9682999849319458,\n",
       "  0.9682999849319458,\n",
       "  0.9684000015258789,\n",
       "  0.9688000082969666,\n",
       "  0.9695000052452087,\n",
       "  0.968500018119812,\n",
       "  0.9696000218391418,\n",
       "  0.9697999954223633,\n",
       "  0.9706000089645386,\n",
       "  0.970300018787384,\n",
       "  0.9707000255584717,\n",
       "  0.9717000126838684]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3255122900009155,\n",
       "  0.5372045040130615,\n",
       "  0.40881624817848206,\n",
       "  0.35611504316329956,\n",
       "  0.32433149218559265,\n",
       "  0.3023306429386139,\n",
       "  0.2850038409233093,\n",
       "  0.2707560658454895,\n",
       "  0.2581365704536438,\n",
       "  0.24710839986801147,\n",
       "  0.2374064326286316,\n",
       "  0.22826285660266876,\n",
       "  0.21982134878635406,\n",
       "  0.212418794631958,\n",
       "  0.20530423521995544,\n",
       "  0.1986558735370636,\n",
       "  0.19244743883609772,\n",
       "  0.1863471269607544,\n",
       "  0.18042941391468048,\n",
       "  0.17505422234535217,\n",
       "  0.17018067836761475,\n",
       "  0.16534046828746796,\n",
       "  0.16064375638961792,\n",
       "  0.1564418524503708,\n",
       "  0.15214723348617554,\n",
       "  0.14815030992031097,\n",
       "  0.1440407633781433,\n",
       "  0.14052394032478333,\n",
       "  0.13696303963661194,\n",
       "  0.13352636992931366,\n",
       "  0.1303326040506363,\n",
       "  0.1270647495985031,\n",
       "  0.12412892282009125,\n",
       "  0.12128923833370209,\n",
       "  0.11832328140735626,\n",
       "  0.11571290343999863,\n",
       "  0.11314880847930908,\n",
       "  0.11052998155355453,\n",
       "  0.10808467864990234,\n",
       "  0.10574314743280411,\n",
       "  0.10353601723909378,\n",
       "  0.10116498917341232,\n",
       "  0.0990108773112297,\n",
       "  0.09724804013967514,\n",
       "  0.09505750983953476,\n",
       "  0.09312532097101212,\n",
       "  0.09108127653598785,\n",
       "  0.08932502567768097,\n",
       "  0.08766568452119827,\n",
       "  0.0858350470662117],\n",
       " 'accuracy': [0.6701200008392334,\n",
       "  0.8660600185394287,\n",
       "  0.8892999887466431,\n",
       "  0.9020199775695801,\n",
       "  0.9095199704170227,\n",
       "  0.9147800207138062,\n",
       "  0.919920027256012,\n",
       "  0.9238399863243103,\n",
       "  0.927079975605011,\n",
       "  0.9306399822235107,\n",
       "  0.9334800243377686,\n",
       "  0.9354199767112732,\n",
       "  0.9380000233650208,\n",
       "  0.9397799968719482,\n",
       "  0.9416400194168091,\n",
       "  0.9434599876403809,\n",
       "  0.9451799988746643,\n",
       "  0.9470999836921692,\n",
       "  0.9484599828720093,\n",
       "  0.9497600197792053,\n",
       "  0.9515600204467773,\n",
       "  0.9536399841308594,\n",
       "  0.954479992389679,\n",
       "  0.9558799862861633,\n",
       "  0.9570800065994263,\n",
       "  0.9581199884414673,\n",
       "  0.9592599868774414,\n",
       "  0.9603999853134155,\n",
       "  0.9613000154495239,\n",
       "  0.9625399708747864,\n",
       "  0.9632999897003174,\n",
       "  0.9637799859046936,\n",
       "  0.9651200175285339,\n",
       "  0.9659199714660645,\n",
       "  0.9670000076293945,\n",
       "  0.9674999713897705,\n",
       "  0.9684799909591675,\n",
       "  0.969219982624054,\n",
       "  0.9697999954223633,\n",
       "  0.9708200097084045,\n",
       "  0.9712799787521362,\n",
       "  0.9724199771881104,\n",
       "  0.9729599952697754,\n",
       "  0.9731799960136414,\n",
       "  0.9737399816513062,\n",
       "  0.9745200276374817,\n",
       "  0.9756600260734558,\n",
       "  0.9760599732398987,\n",
       "  0.9763200283050537,\n",
       "  0.9769600033760071],\n",
       " 'val_loss': [0.6281177401542664,\n",
       "  0.40436363220214844,\n",
       "  0.3392876982688904,\n",
       "  0.30645108222961426,\n",
       "  0.28525736927986145,\n",
       "  0.26911675930023193,\n",
       "  0.255307137966156,\n",
       "  0.24428537487983704,\n",
       "  0.23442253470420837,\n",
       "  0.22670897841453552,\n",
       "  0.21861164271831512,\n",
       "  0.2109338939189911,\n",
       "  0.2057771235704422,\n",
       "  0.19770444929599762,\n",
       "  0.19271601736545563,\n",
       "  0.18722251057624817,\n",
       "  0.183098703622818,\n",
       "  0.17834094166755676,\n",
       "  0.17427848279476166,\n",
       "  0.16991783678531647,\n",
       "  0.1656085103750229,\n",
       "  0.1624239981174469,\n",
       "  0.15772777795791626,\n",
       "  0.15420329570770264,\n",
       "  0.15195980668067932,\n",
       "  0.148654043674469,\n",
       "  0.14706045389175415,\n",
       "  0.14280231297016144,\n",
       "  0.14080189168453217,\n",
       "  0.1387983113527298,\n",
       "  0.1351936310529709,\n",
       "  0.1362297087907791,\n",
       "  0.13241741061210632,\n",
       "  0.12896467745304108,\n",
       "  0.12823767960071564,\n",
       "  0.12662698328495026,\n",
       "  0.12356060743331909,\n",
       "  0.12246999144554138,\n",
       "  0.12082535028457642,\n",
       "  0.11897719651460648,\n",
       "  0.1178629994392395,\n",
       "  0.11649017035961151,\n",
       "  0.1155075952410698,\n",
       "  0.11489889770746231,\n",
       "  0.11295842379331589,\n",
       "  0.11151543259620667,\n",
       "  0.11040890216827393,\n",
       "  0.1089898943901062,\n",
       "  0.10812518000602722,\n",
       "  0.10673903673887253],\n",
       " 'val_accuracy': [0.8619999885559082,\n",
       "  0.8956999778747559,\n",
       "  0.9063000082969666,\n",
       "  0.9140999913215637,\n",
       "  0.9174000024795532,\n",
       "  0.9230999946594238,\n",
       "  0.9273999929428101,\n",
       "  0.9318000078201294,\n",
       "  0.9341999888420105,\n",
       "  0.9359999895095825,\n",
       "  0.9390000104904175,\n",
       "  0.9416000247001648,\n",
       "  0.9419000148773193,\n",
       "  0.9458000063896179,\n",
       "  0.9472000002861023,\n",
       "  0.9480000138282776,\n",
       "  0.9503999948501587,\n",
       "  0.9513000249862671,\n",
       "  0.9527999758720398,\n",
       "  0.9537000060081482,\n",
       "  0.9559999704360962,\n",
       "  0.9563999772071838,\n",
       "  0.9577000141143799,\n",
       "  0.9589999914169312,\n",
       "  0.9593999981880188,\n",
       "  0.9607999920845032,\n",
       "  0.9610999822616577,\n",
       "  0.9617000222206116,\n",
       "  0.9632999897003174,\n",
       "  0.9621000289916992,\n",
       "  0.9639000296592712,\n",
       "  0.9641000032424927,\n",
       "  0.965399980545044,\n",
       "  0.9664000272750854,\n",
       "  0.9666000008583069,\n",
       "  0.9657999873161316,\n",
       "  0.9678999781608582,\n",
       "  0.9671000242233276,\n",
       "  0.9682999849319458,\n",
       "  0.9682999849319458,\n",
       "  0.9684000015258789,\n",
       "  0.9688000082969666,\n",
       "  0.9695000052452087,\n",
       "  0.968500018119812,\n",
       "  0.9696000218391418,\n",
       "  0.9697999954223633,\n",
       "  0.9706000089645386,\n",
       "  0.970300018787384,\n",
       "  0.9707000255584717,\n",
       "  0.9717000126838684]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.325512</td>\n",
       "      <td>0.67012</td>\n",
       "      <td>0.628118</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537205</td>\n",
       "      <td>0.86606</td>\n",
       "      <td>0.404364</td>\n",
       "      <td>0.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408816</td>\n",
       "      <td>0.88930</td>\n",
       "      <td>0.339288</td>\n",
       "      <td>0.9063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356115</td>\n",
       "      <td>0.90202</td>\n",
       "      <td>0.306451</td>\n",
       "      <td>0.9141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.324331</td>\n",
       "      <td>0.90952</td>\n",
       "      <td>0.285257</td>\n",
       "      <td>0.9174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.302331</td>\n",
       "      <td>0.91478</td>\n",
       "      <td>0.269117</td>\n",
       "      <td>0.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.285004</td>\n",
       "      <td>0.91992</td>\n",
       "      <td>0.255307</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.270756</td>\n",
       "      <td>0.92384</td>\n",
       "      <td>0.244285</td>\n",
       "      <td>0.9318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.258137</td>\n",
       "      <td>0.92708</td>\n",
       "      <td>0.234423</td>\n",
       "      <td>0.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.247108</td>\n",
       "      <td>0.93064</td>\n",
       "      <td>0.226709</td>\n",
       "      <td>0.9360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.237406</td>\n",
       "      <td>0.93348</td>\n",
       "      <td>0.218612</td>\n",
       "      <td>0.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.228263</td>\n",
       "      <td>0.93542</td>\n",
       "      <td>0.210934</td>\n",
       "      <td>0.9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.219821</td>\n",
       "      <td>0.93800</td>\n",
       "      <td>0.205777</td>\n",
       "      <td>0.9419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.212419</td>\n",
       "      <td>0.93978</td>\n",
       "      <td>0.197704</td>\n",
       "      <td>0.9458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.205304</td>\n",
       "      <td>0.94164</td>\n",
       "      <td>0.192716</td>\n",
       "      <td>0.9472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.198656</td>\n",
       "      <td>0.94346</td>\n",
       "      <td>0.187223</td>\n",
       "      <td>0.9480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.192447</td>\n",
       "      <td>0.94518</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.186347</td>\n",
       "      <td>0.94710</td>\n",
       "      <td>0.178341</td>\n",
       "      <td>0.9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.180429</td>\n",
       "      <td>0.94846</td>\n",
       "      <td>0.174278</td>\n",
       "      <td>0.9528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.175054</td>\n",
       "      <td>0.94976</td>\n",
       "      <td>0.169918</td>\n",
       "      <td>0.9537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.170181</td>\n",
       "      <td>0.95156</td>\n",
       "      <td>0.165609</td>\n",
       "      <td>0.9560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.165340</td>\n",
       "      <td>0.95364</td>\n",
       "      <td>0.162424</td>\n",
       "      <td>0.9564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.160644</td>\n",
       "      <td>0.95448</td>\n",
       "      <td>0.157728</td>\n",
       "      <td>0.9577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.156442</td>\n",
       "      <td>0.95588</td>\n",
       "      <td>0.154203</td>\n",
       "      <td>0.9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.152147</td>\n",
       "      <td>0.95708</td>\n",
       "      <td>0.151960</td>\n",
       "      <td>0.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.95812</td>\n",
       "      <td>0.148654</td>\n",
       "      <td>0.9608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.144041</td>\n",
       "      <td>0.95926</td>\n",
       "      <td>0.147060</td>\n",
       "      <td>0.9611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.140524</td>\n",
       "      <td>0.96040</td>\n",
       "      <td>0.142802</td>\n",
       "      <td>0.9617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.136963</td>\n",
       "      <td>0.96130</td>\n",
       "      <td>0.140802</td>\n",
       "      <td>0.9633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.133526</td>\n",
       "      <td>0.96254</td>\n",
       "      <td>0.138798</td>\n",
       "      <td>0.9621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.130333</td>\n",
       "      <td>0.96330</td>\n",
       "      <td>0.135194</td>\n",
       "      <td>0.9639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.127065</td>\n",
       "      <td>0.96378</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.124129</td>\n",
       "      <td>0.96512</td>\n",
       "      <td>0.132417</td>\n",
       "      <td>0.9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.121289</td>\n",
       "      <td>0.96592</td>\n",
       "      <td>0.128965</td>\n",
       "      <td>0.9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.118323</td>\n",
       "      <td>0.96700</td>\n",
       "      <td>0.128238</td>\n",
       "      <td>0.9666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.115713</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.126627</td>\n",
       "      <td>0.9658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.113149</td>\n",
       "      <td>0.96848</td>\n",
       "      <td>0.123561</td>\n",
       "      <td>0.9679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.110530</td>\n",
       "      <td>0.96922</td>\n",
       "      <td>0.122470</td>\n",
       "      <td>0.9671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.108085</td>\n",
       "      <td>0.96980</td>\n",
       "      <td>0.120825</td>\n",
       "      <td>0.9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.105743</td>\n",
       "      <td>0.97082</td>\n",
       "      <td>0.118977</td>\n",
       "      <td>0.9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.103536</td>\n",
       "      <td>0.97128</td>\n",
       "      <td>0.117863</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.101165</td>\n",
       "      <td>0.97242</td>\n",
       "      <td>0.116490</td>\n",
       "      <td>0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.099011</td>\n",
       "      <td>0.97296</td>\n",
       "      <td>0.115508</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.097248</td>\n",
       "      <td>0.97318</td>\n",
       "      <td>0.114899</td>\n",
       "      <td>0.9685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.095058</td>\n",
       "      <td>0.97374</td>\n",
       "      <td>0.112958</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.093125</td>\n",
       "      <td>0.97452</td>\n",
       "      <td>0.111515</td>\n",
       "      <td>0.9698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.091081</td>\n",
       "      <td>0.97566</td>\n",
       "      <td>0.110409</td>\n",
       "      <td>0.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.089325</td>\n",
       "      <td>0.97606</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.9703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.087666</td>\n",
       "      <td>0.97632</td>\n",
       "      <td>0.108125</td>\n",
       "      <td>0.9707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.085835</td>\n",
       "      <td>0.97696</td>\n",
       "      <td>0.106739</td>\n",
       "      <td>0.9717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.325512   0.67012  0.628118        0.8620\n",
       "1   0.537205   0.86606  0.404364        0.8957\n",
       "2   0.408816   0.88930  0.339288        0.9063\n",
       "3   0.356115   0.90202  0.306451        0.9141\n",
       "4   0.324331   0.90952  0.285257        0.9174\n",
       "5   0.302331   0.91478  0.269117        0.9231\n",
       "6   0.285004   0.91992  0.255307        0.9274\n",
       "7   0.270756   0.92384  0.244285        0.9318\n",
       "8   0.258137   0.92708  0.234423        0.9342\n",
       "9   0.247108   0.93064  0.226709        0.9360\n",
       "10  0.237406   0.93348  0.218612        0.9390\n",
       "11  0.228263   0.93542  0.210934        0.9416\n",
       "12  0.219821   0.93800  0.205777        0.9419\n",
       "13  0.212419   0.93978  0.197704        0.9458\n",
       "14  0.205304   0.94164  0.192716        0.9472\n",
       "15  0.198656   0.94346  0.187223        0.9480\n",
       "16  0.192447   0.94518  0.183099        0.9504\n",
       "17  0.186347   0.94710  0.178341        0.9513\n",
       "18  0.180429   0.94846  0.174278        0.9528\n",
       "19  0.175054   0.94976  0.169918        0.9537\n",
       "20  0.170181   0.95156  0.165609        0.9560\n",
       "21  0.165340   0.95364  0.162424        0.9564\n",
       "22  0.160644   0.95448  0.157728        0.9577\n",
       "23  0.156442   0.95588  0.154203        0.9590\n",
       "24  0.152147   0.95708  0.151960        0.9594\n",
       "25  0.148150   0.95812  0.148654        0.9608\n",
       "26  0.144041   0.95926  0.147060        0.9611\n",
       "27  0.140524   0.96040  0.142802        0.9617\n",
       "28  0.136963   0.96130  0.140802        0.9633\n",
       "29  0.133526   0.96254  0.138798        0.9621\n",
       "30  0.130333   0.96330  0.135194        0.9639\n",
       "31  0.127065   0.96378  0.136230        0.9641\n",
       "32  0.124129   0.96512  0.132417        0.9654\n",
       "33  0.121289   0.96592  0.128965        0.9664\n",
       "34  0.118323   0.96700  0.128238        0.9666\n",
       "35  0.115713   0.96750  0.126627        0.9658\n",
       "36  0.113149   0.96848  0.123561        0.9679\n",
       "37  0.110530   0.96922  0.122470        0.9671\n",
       "38  0.108085   0.96980  0.120825        0.9683\n",
       "39  0.105743   0.97082  0.118977        0.9683\n",
       "40  0.103536   0.97128  0.117863        0.9684\n",
       "41  0.101165   0.97242  0.116490        0.9688\n",
       "42  0.099011   0.97296  0.115508        0.9695\n",
       "43  0.097248   0.97318  0.114899        0.9685\n",
       "44  0.095058   0.97374  0.112958        0.9696\n",
       "45  0.093125   0.97452  0.111515        0.9698\n",
       "46  0.091081   0.97566  0.110409        0.9706\n",
       "47  0.089325   0.97606  0.108990        0.9703\n",
       "48  0.087666   0.97632  0.108125        0.9707\n",
       "49  0.085835   0.97696  0.106739        0.9717"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09250835329294205, 0.9733999967575073]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.002, 0.   , 0.   , 0.   , 0.998, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pred_test[4])\n",
    "plt.imshow(X_test[4].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8032 - val_loss: 5.8649\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 2.0676\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 1.0803\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 6.7461\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 14.1063\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5615 - val_loss: 3.1107\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 8.1835\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4377 - val_loss: 3.2079\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4081 - val_loss: 0.3650\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3585\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.4298\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3748 - val_loss: 0.3506\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3580\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.3912\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3631 - val_loss: 0.3451\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3611 - val_loss: 0.3502\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3586 - val_loss: 0.3366\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3404\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3525 - val_loss: 0.3424\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3391\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid), \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3513\n",
      "0.3512588143348694\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:2000])\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3688646336538541\n",
      "0.7233715492146345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(mean_squared_error(y_test[:2000], y_pred))\n",
    "print(r2_score(y_test[:2000], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "      <td>2.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "      <td>1.153956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>0.149990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "      <td>1.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "      <td>1.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "      <td>2.647250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "      <td>5.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude        target  \n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704      2.068558  \n",
       "std       10.386050      2.135952      2.003532      1.153956  \n",
       "min        0.692308     32.540000   -124.350000      0.149990  \n",
       "25%        2.429741     33.930000   -121.800000      1.196000  \n",
       "50%        2.818116     34.260000   -118.490000      1.797000  \n",
       "75%        3.282261     37.710000   -118.010000      2.647250  \n",
       "max     1243.333333     41.950000   -114.310000      5.000010  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pickle.load(open(\"model.pkl\", \"rb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3916\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3646\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3593\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3557\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3524\n",
      "Epoch 6/30\n",
      " 97/363 [=======>......................] - ETA: 0s - loss: 0.3330"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25972\\577377571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                    callbacks = [checkpoint_cb])\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1641\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1642\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1643\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1373\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    637\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    641\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \"\"\"\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    704\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 697\u001b[1;33m           self.handle, self._dtype)\n\u001b[0m\u001b[0;32m    698\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 581\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    582\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"callback_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x22483cc17c8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3315 - val_loss: 0.3351\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3404\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3460\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=2)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
