{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aquí encontrarás todo lo que necesitas saber: https://www.kaggle.com/t/ab8726f0cfc84544abbae69a6be88071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Para que funcione necesitas bajarte los archivos de datos de Kaggle \n",
    "train = pd.read_csv(r\"C:\\Users\\Joan Oliver\\TheBridge-DataScienceBootcamp\\data-science-pt-2023-01\\Machine_Learning\\1-Supervisado\\1-Regression\\Kaggle1\\data\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\Joan Oliver\\TheBridge-DataScienceBootcamp\\data-science-pt-2023-01\\Machine_Learning\\1-Supervisado\\1-Regression\\Kaggle1\\data\\test.csv\")\n",
    "sample_submission = pd.read_csv(r\"C:\\Users\\Joan Oliver\\TheBridge-DataScienceBootcamp\\data-science-pt-2023-01\\Machine_Learning\\1-Supervisado\\1-Regression\\Kaggle1\\data\\sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 912 entries, 0 to 911\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   laptop_ID         912 non-null    int64  \n",
      " 1   Company           912 non-null    object \n",
      " 2   Product           912 non-null    object \n",
      " 3   TypeName          912 non-null    object \n",
      " 4   Inches            912 non-null    float64\n",
      " 5   ScreenResolution  912 non-null    object \n",
      " 6   Cpu               912 non-null    object \n",
      " 7   Ram               912 non-null    object \n",
      " 8   Memory            912 non-null    object \n",
      " 9   Gpu               912 non-null    object \n",
      " 10  OpSys             912 non-null    object \n",
      " 11  Weight            912 non-null    object \n",
      " 12  Price_euros       912 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 92.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = train.copy()\n",
    "data_df.drop([\"laptop_ID\", \"Product\", \"Weight\"], axis=1, inplace=True)\n",
    "res_lst = list(data_df[\"ScreenResolution\"])\n",
    "\n",
    "resolutions = []\n",
    "for item in res_lst:\n",
    "    match = re.search(r'(\\d+x\\d+)', item)\n",
    "    if match:\n",
    "        resolutions.append(match.group(0))\n",
    "\n",
    "data_df[\"Resolution\"] = pd.Series(resolutions)\n",
    "data_df[\"Width\"] = data_df[\"Resolution\"].str.split(\"x\").str[0].astype(int)\n",
    "# data_df[\"Height\"] = data_df[\"Resolution\"].str.split(\"x\").str[1].astype(int)\n",
    "data_df[\"Cpu_Provider\"] = data_df[\"Cpu\"].str.split(\" \").str[0]\n",
    "# data_df[\"Gpu_Provider\"] = data_df[\"Gpu\"].str.split(\" \").str[0]\n",
    "data_df[\"GHz\"]  = data_df[\"Cpu\"].str.split(\" \").str[-1].str.replace(\"GHz\", \"\").astype(float)\n",
    "# data_df[\"Weight\"] = data_df[\"Weight\"].str.replace(\"kg\", \"\").astype(float)\n",
    "data_df[\"Memory\"].unique()\n",
    "memory_lst = list(data_df[\"Memory\"].str.split(\" \").str[0])\n",
    "\n",
    "memory = []\n",
    "for item in memory_lst:\n",
    "    match = re.search(r'(\\d+)', item)\n",
    "    if match:\n",
    "        memory.append(float(match.group(0)))\n",
    "data_df[\"Memory_1\"] = pd.Series(memory)\n",
    "data_df[\"Memory_1\"].unique()\n",
    "memory_lst = list(data_df[\"Memory\"].str.split(\" + \").str[1])\n",
    "memory = []\n",
    "for item in memory_lst:\n",
    "    try:\n",
    "        match = re.search(r'(\\d+)', item)\n",
    "        if match:\n",
    "            memory.append(int(str(match.group(0))))\n",
    "    except:\n",
    "        memory.append(0)\n",
    "# data_df[\"Memory_2\"] = pd.Series(memory)\n",
    "tb = (data_df[\"Memory_1\"] < 5) & (0 < data_df[\"Memory_1\"])\n",
    "data_df.loc[tb,\"Memory_1\"] *= 1000\n",
    "data_df.loc[tb]\n",
    "# tb = (data_df[\"Memory_2\"] < 5) & (0 < data_df[\"Memory_2\"])\n",
    "# data_df.loc[tb,\"Memory_2\"] *= 1000\n",
    "# data_df[\"Storage_1\"] = data_df[\"Memory\"].str.split(\" + \").str[0].str.split(\" \").str[1]\n",
    "data_df[\"Storage_2\"] = data_df[\"Memory\"].str.split(\" + \").str[1].str.split(\" \").str[1].fillna(0)\n",
    "data_df[\"Ram\"] = data_df[\"Ram\"].str.replace(\"GB\", \"\").astype(float)\n",
    "data_df[\"OpSys\"].replace('Mac OS X', 'macOS X', inplace=True)\n",
    "data_df[\"OpSys_provider\"] = data_df[\"OpSys\"].str.split(\" \").str[0]\n",
    "\n",
    "# ML\n",
    "\n",
    "ml_data_df = data_df.copy()\n",
    "ml_data_df.drop([\"ScreenResolution\", \n",
    "                \"Memory\",\n",
    "                \"Cpu\",\n",
    "                \"Memory\",\n",
    "                \"Gpu\",\n",
    "                \"Resolution\",\n",
    "                # \"Height\"\n",
    "                ], \n",
    "                axis=1, inplace=True)\n",
    "\n",
    "cat_lst = [\"TypeName\", \n",
    "           \"Company\", \n",
    "           \"OpSys\", \n",
    "           \"Cpu_Provider\", \n",
    "        #    \"Gpu_Provider\", \n",
    "        #    \"Storage_1\", \n",
    "           \"Storage_2\", \n",
    "           \"OpSys_provider\"]\n",
    "\n",
    "for cat in cat_lst:\n",
    "    company = list(enumerate(ml_data_df[cat].unique().tolist()))\n",
    "    company_dict = {company[i][1] : company[i][0] for i in range(len(company))}\n",
    "    ml_data_df[cat] = ml_data_df[cat].map(company_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Inches</th>\n",
       "      <th>Ram</th>\n",
       "      <th>OpSys</th>\n",
       "      <th>Price_euros</th>\n",
       "      <th>Width</th>\n",
       "      <th>Cpu_Provider</th>\n",
       "      <th>GHz</th>\n",
       "      <th>Memory_1</th>\n",
       "      <th>Storage_2</th>\n",
       "      <th>OpSys_provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>1366</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>3200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  TypeName  Inches  Ram  OpSys  Price_euros  Width  Cpu_Provider  \\\n",
       "0        0         0    15.6  4.0      0        387.0   1366             0   \n",
       "1        1         1    13.3  8.0      0       1379.0   3200             1   \n",
       "2        0         0    17.3  8.0      0        854.0   1920             1   \n",
       "3        2         2    12.5  8.0      0       1483.0   1920             1   \n",
       "4        3         0    17.3  8.0      0        519.0   1600             0   \n",
       "\n",
       "   GHz  Memory_1  Storage_2  OpSys_provider  \n",
       "0  2.2     500.0          0               0  \n",
       "1  2.4     256.0          0               0  \n",
       "2  1.6     256.0          0               0  \n",
       "3  2.7     512.0          0               0  \n",
       "4  2.5    1000.0          0               0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ml_data_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasos que si o si debéis realizar para poder participar en la competición:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definir X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(['Price_euros'], axis=1)\n",
    "y = train['Price_euros'].copy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dividir X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Asignar el modelo (vacío) a una variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 266.16465959362455\n",
      "MSE: 110385.35024797906\n",
      "RMSE: 332.2429084991568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lm = LinearRegression() \n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "predictions = lm.predict(X_test)\n",
    "# print(predictions)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136439829290595"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Standarizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scal = std_scale.transform(X_train)\n",
    "X_test_scal = std_scale.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ram</th>\n",
       "      <td>335.729984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <td>156.739492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHz</th>\n",
       "      <td>129.989227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpSys</th>\n",
       "      <td>118.385294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TypeName</th>\n",
       "      <td>102.336739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cpu_Provider</th>\n",
       "      <td>74.247324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <td>36.555761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inches</th>\n",
       "      <td>-19.252775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Storage_2</th>\n",
       "      <td>-41.756788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memory_1</th>\n",
       "      <td>-67.820976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpSys_provider</th>\n",
       "      <td>-116.587733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coefficient\n",
       "Ram              335.729984\n",
       "Width            156.739492\n",
       "GHz              129.989227\n",
       "OpSys            118.385294\n",
       "TypeName         102.336739\n",
       "Cpu_Provider      74.247324\n",
       "Company           36.555761\n",
       "Inches           -19.252775\n",
       "Storage_2        -41.756788\n",
       "Memory_1         -67.820976\n",
       "OpSys_provider  -116.587733"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_scal = LinearRegression()\n",
    "lm_scal.fit(X_train_scal, y_train)\n",
    "\n",
    "predictions = lm_scal.predict(X_test_scal)\n",
    "# print(predictions)\n",
    "\n",
    "intercept_scal = lm_scal.intercept_\n",
    "features_std = pd.DataFrame(lm_scal.coef_, X_train.columns, columns=['coefficient'])\n",
    "\n",
    "features_std.sort_values('coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'TypeName', 'Inches', 'Ram', 'OpSys', 'Price_euros', 'Width',\n",
       "       'Cpu_Provider', 'GHz', 'Memory_1', 'Storage_2', 'OpSys_provider'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 266.1646595936247\n",
      "MSE: 110385.35024797916\n",
      "RMSE: 332.24290849915695\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "poly_features.fit(X_train)\n",
    "X_poly = poly_features.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866 866\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, X_train, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_reg = LinearRegression()\n",
    "pol_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pol_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (866, 11), indices imply (866, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_288\\3164256993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m                     \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m                     \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m                 )\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (866, 11), indices imply (866, 1)"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(pol_reg.predict(X_poly), columns = ['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (866, 11), indices imply (866, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_288\\3855971456.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'real_value'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_preds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m                     \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m                     \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m                 )\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (866, 11), indices imply (866, 1)"
     ]
    }
   ],
   "source": [
    "df_preds = pd.DataFrame(pol_reg.predict(X_poly), columns = ['predictions'])\n",
    "df_preds['real_value'] = pd.Series(y_test)\n",
    "\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sacar métricas, valorar el modelo \n",
    "\n",
    "Recuerda que en la competición se va a evaluar con la métrica de MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n",
    "print(mae)\n",
    "print(lm_scal.score(X_test_scal, y_test))\n",
    "print(lm_scal.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una vez listo el modelo, toca predecir con el dataset de predicción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de **modelo que está listo**. \n",
    "\n",
    "Tras hacer suficientes pruebas, analizar los datos, hacer feature engineering, probar diferentes modelos con diferentes parámetros, es con este con el que observo mejores métricas y menos overfitting. ¡Cuidado con el overfitting aquí! Si vuestro modelo aprende muy bien de estos datos pero hay overfitting cuando le pasemos los datos desconocidos de `test.csv` nos arriesgamos a que digamos, no salga lo esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Entrena dicho modelo con TODOS tus datos de train, esto es con `train.csv` al completo.\n",
    "\n",
    "\n",
    "**CON LAS TRANSFORMACIONES QUE LE HAYAS REALIZADO A `X` INCLUÍDAS.**\n",
    "\n",
    "\n",
    "Véase:\n",
    "- Estandarización/Normalización\n",
    "- Eliminación de Outliers\n",
    "- Eliminación de columnas\n",
    "- Creación de columnas nuevas\n",
    "- Gestión de valores nulos\n",
    "- Y un largo etcétera de técnicas que como Data Scientist hayas considerado las mejores para tu dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carga los datos de `test.csv` para predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pd.read_csv(\"data/test.csv\")\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = X_pred.copy()\n",
    "data_df.drop([\"laptop_ID\", \"Product\", \"Weight\"], axis=1, inplace=True)\n",
    "res_lst = list(data_df[\"ScreenResolution\"])\n",
    "\n",
    "resolutions = []\n",
    "for item in res_lst:\n",
    "    match = re.search(r'(\\d+x\\d+)', item)\n",
    "    if match:\n",
    "        resolutions.append(match.group(0))\n",
    "\n",
    "data_df[\"Resolution\"] = pd.Series(resolutions)\n",
    "data_df[\"Width\"] = data_df[\"Resolution\"].str.split(\"x\").str[0].astype(int)\n",
    "# data_df[\"Height\"] = data_df[\"Resolution\"].str.split(\"x\").str[1].astype(int)\n",
    "data_df[\"Cpu_Provider\"] = data_df[\"Cpu\"].str.split(\" \").str[0]\n",
    "# data_df[\"Gpu_Provider\"] = data_df[\"Gpu\"].str.split(\" \").str[0]\n",
    "data_df[\"GHz\"]  = data_df[\"Cpu\"].str.split(\" \").str[-1].str.replace(\"GHz\", \"\").astype(float)\n",
    "# data_df[\"Weight\"] = data_df[\"Weight\"].str.replace(\"kg\", \"\").astype(float)\n",
    "data_df[\"Memory\"].unique()\n",
    "memory_lst = list(data_df[\"Memory\"].str.split(\" \").str[0])\n",
    "\n",
    "memory = []\n",
    "for item in memory_lst:\n",
    "    match = re.search(r'(\\d+)', item)\n",
    "    if match:\n",
    "        memory.append(float(match.group(0)))\n",
    "data_df[\"Memory_1\"] = pd.Series(memory)\n",
    "data_df[\"Memory_1\"].unique()\n",
    "memory_lst = list(data_df[\"Memory\"].str.split(\" + \").str[1])\n",
    "memory = []\n",
    "for item in memory_lst:\n",
    "    try:\n",
    "        match = re.search(r'(\\d+)', item)\n",
    "        if match:\n",
    "            memory.append(int(str(match.group(0))))\n",
    "    except:\n",
    "        memory.append(0)\n",
    "data_df[\"Memory_2\"] = pd.Series(memory)\n",
    "tb = (data_df[\"Memory_1\"] < 5) & (0 < data_df[\"Memory_1\"])\n",
    "data_df.loc[tb,\"Memory_1\"] *= 1000\n",
    "data_df.loc[tb]\n",
    "tb = (data_df[\"Memory_2\"] < 5) & (0 < data_df[\"Memory_2\"])\n",
    "data_df.loc[tb,\"Memory_2\"] *= 1000\n",
    "# data_df[\"Storage_1\"] = data_df[\"Memory\"].str.split(\" + \").str[0].str.split(\" \").str[1]\n",
    "data_df[\"Storage_2\"] = data_df[\"Memory\"].str.split(\" + \").str[1].str.split(\" \").str[1].fillna(0)\n",
    "data_df[\"Ram\"] = data_df[\"Ram\"].str.replace(\"GB\", \"\").astype(float)\n",
    "data_df[\"OpSys\"].replace('Mac OS X', 'macOS X', inplace=True)\n",
    "data_df[\"OpSys_provider\"] = data_df[\"OpSys\"].str.split(\" \").str[0]\n",
    "\n",
    "# ML\n",
    "\n",
    "ml_data_df = data_df.copy()\n",
    "ml_data_df.drop([\"ScreenResolution\", \n",
    "                \"Memory\",\n",
    "                \"Cpu\",\n",
    "                \"Memory\",\n",
    "                \"Gpu\",\n",
    "                \"Resolution\",\n",
    "                # \"Height\"\n",
    "                ], \n",
    "                axis=1, inplace=True)\n",
    "\n",
    "cat_lst = [\"TypeName\", \n",
    "           \"Company\", \n",
    "           \"OpSys\", \n",
    "           \"Cpu_Provider\", \n",
    "        #    \"Gpu_Provider\", \n",
    "        #    \"Storage_1\", \n",
    "           \"Storage_2\", \n",
    "           \"OpSys_provider\"]\n",
    "\n",
    "for cat in cat_lst:\n",
    "    company = list(enumerate(ml_data_df[cat].unique().tolist()))\n",
    "    company_dict = {company[i][1] : company[i][0] for i in range(len(company))}\n",
    "    ml_data_df[cat] = ml_data_df[cat].map(company_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = ml_data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X_pred)\n",
    "X_pred_scal = std_scale.transform(X_pred)\n",
    "\n",
    "predictions = lm_scal.predict(X_pred_scal)\n",
    "\n",
    "intercept_scal = lm_scal.intercept_\n",
    "features_std = pd.DataFrame(lm_scal.coef_, X_pred.columns, columns=['coefficient'])\n",
    "\n",
    "features_std.sort_values('coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"laptop_ID\": sample[\"laptop_ID\"], \"Price_euros\": pred_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANTE: APLICAR LO MISMO A ESTOS DATOS QUE HAYÁIS APLICADO A LOS DATOS DE ENTRENAMIENTO\n",
    "\n",
    "- SI EL ARRAY CON EL QUE HICISTEIS `.fit()` ERA DE 4 COLUMNAS, PARA `.predict()` DEBEN SER LAS MISMAS\n",
    "- SI AL ARRAY CON EL QUE HICISTEIS `.fit()` LO NORMALIZASTEIS, PARA `.predict()` DEBÉIS NORMALIZARLO\n",
    "- TODO IGUAL SALVO BORRAR FILAS, EL NÚMERO DE ROWS SE DEBE MANTENER EN ESTE SET, PUES LA PREDICCIÓN DEBE TENER 391 FILAS, SI O SI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entonces, si al cargar los datos de train usé `index_col=0` para que utilizara la primera columna del conjunto de datos como índice, ¿tendré que hacerlo también para el conjunto `test.csv`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué opináis?\n",
    "# Sí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tierraljelechu.com/web/img/wiki_up/1.996-SorpresaDto.-1-Red.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pd.read_csv(\"Dataset/test.csv\", index_col=0)\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. AHORA puedo hacer la predicción que será lo que subirás a Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué es lo que subirás a Kaggle?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_submit = model.predict(X_pred)\n",
    "predictions_submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡PERO! Para subir a Kaggle la predicción, ésta tendrá que tener una forma específica y no valdrá otra.**\n",
    "\n",
    "En este caso, la **MISMA** forma que `sample_submission.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"Dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mete tus predicciones en un dataframe. \n",
    "\n",
    "En este caso, la **MISMA** forma que `sample_submission.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"laptop_ID\": sample[\"laptop_ID\"], \"Price_euros\": predictions_submit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pásale el CHEQUEATOR para comprobar que efectivamente está listo para subir a Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aún no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. También tú.\n",
    "    \"\"\"\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.laptop_ID.all() == sample.laptop_ID.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                submission.to_csv(\"submission_1.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que después de todo este notebook hayas hecho algún cambio en las filas de `diamonds_test.csv`. Lloro.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
